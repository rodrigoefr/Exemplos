import Modelo
import QLearning

# escolher conjunto de estudantes

for x in range(30):
    

    estudante  = Modelo.Estudante()
estudante2  = Modelo.Estudante()
estudante3  = Modelo.Estudante()
estudante4  = Modelo.Estudante()
estudante5  = Modelo.Estudante()
estudante6  = Modelo.Estudante()
estudante7  = Modelo.Estudante()
estudante8  = Modelo.Estudante()
estudante9  = Modelo.Estudante()
estudante10 = Modelo.Estudante()

listaEstudantes = []
listaEstudantes.append(estudante1)
listaEstudantes.append(estudante2)
listaEstudantes.append(estudante3)
listaEstudantes.append(estudante4)
listaEstudantes.append(estudante5)
listaEstudantes.append(estudante6)
listaEstudantes.append(estudante7)
listaEstudantes.append(estudante8)
listaEstudantes.append(estudante9)
listaEstudantes.append(estudante10)


for estudante in listaEstudantes:
  print (estudante.nota)



print(estudante.conceitosAprendidos.nota_compreensao_sw_codigofonte)


# definir objetivos pedagogicos
#   - maximizar nota geral


# definir materiais didaticos

acoesPedagogicas  = Modelo.AcoesPedagogicas()
for acao in acoesPedagogicas.listaAcoes:
    print(acao.nome)
    print("\n")    

qLearning = QLearning.QLearning();

print (qLearning.tabelaQ)

--------------------------------------------------------------------------------------------------------------------------------------------------------

https://www.coursera.org/learn/scala-spark-big-data/supplement/R7FJ9/eclipse-tutorial



---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


--- instalar jupyter notebook

- instalar anaconda

download

bash Anaconda(..).sh

- instaladr apache toree

download

pip install pyspark

pip install toree-(...).tar.gz
pip install toree

jupyter toree install --spark_home=$SPARK_HOME --interpreters=Scala,PySpark,SQL --user	

jupyter toree install --spark_home=$SPARK_HOME --interpreters=PySpark   
obs: no caso de erro no pyspark

jupyter notebook --no-browser

jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser

-Obs
funcionou com scala
porém o pyspark não apareceu


-------- configurar pyspark em jupyter notebook

https://www.sicara.ai/blog/2017-05-02-get-started-pyspark-jupyter-notebook-3-minutes

Method 1 — Configure PySpark driver
Update PySpark driver environment variables: add these lines to your ~/.bashrc (or ~/.zshrc) file.

export PYSPARK_DRIVER_PYTHON=jupyter
export PYSPARK_DRIVER_PYTHON_OPTS='notebook'

Restart your terminal and launch PySpark again:

$ pyspark


Method 2 — FindSpark package

To install findspark:
$ pip install findspark

Launch a regular Jupyter Notebook:
$ jupyter notebook

Create a new Python [default] notebook and write 
